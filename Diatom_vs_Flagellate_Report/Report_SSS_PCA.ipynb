{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "071b0355",
   "metadata": {},
   "source": [
    "# Surface Salinity PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447063d9",
   "metadata": {},
   "source": [
    "After we have proved that salinity is a good tracer for total nitrate, including the part consumed by phytoplankton, we can now begin our analysis on surface salinity, which is a good indicator for both nitrate and see water movement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf4e342",
   "metadata": {},
   "source": [
    "## PCA 2011&2018 Summer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61580ed",
   "metadata": {},
   "source": [
    "In order to make sure that our PCA will not mix different modes, I intend to conduct PCA on summers of 2011 and 2018 and check if they share PCs and Modes which have the same physical explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5b5c3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing Year 2011 (May 1 - Aug 31) ---\n",
      "  Data shape: (123, 2880)\n",
      "\n",
      "--- Analyzing Year 2018 (May 1 - Aug 31) ---\n",
      "  Data shape: (123, 2880)\n",
      "\n",
      "--- Generating Comparison Plots ---\n",
      "Saved comparison map: /home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA/Compare_Spatial_Mode_1.png\n",
      "Saved comparison TS: /home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA/Compare_TimeSeries_PC_1.svg\n",
      "Saved comparison map: /home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA/Compare_Spatial_Mode_2.png\n",
      "Saved comparison TS: /home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA/Compare_TimeSeries_PC_2.svg\n",
      "Saved comparison map: /home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA/Compare_Spatial_Mode_3.png\n",
      "Saved comparison TS: /home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA/Compare_TimeSeries_PC_3.svg\n",
      "\n",
      "Done! Check folder: /home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA/\n",
      "Tip: If EOF-1 maps look similar (e.g., both river plume patterns), you can safely combine years.\n"
     ]
    }
   ],
   "source": [
    "# SSS_PCA_Comparison_2011_vs_2018.py\n",
    "# Performs independent PCA on Sea Surface Salinity (SSS) for:\n",
    "# 1. Summer 2011 (May 1 - Aug 31)\n",
    "# 2. Summer 2018 (May 1 - Aug 31)\n",
    "# And generates side-by-side comparison plots to check for consistency.\n",
    "\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature \n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "# !!! 请根据实际环境修改 !!!\n",
    "BASE_DIR = '/results2/SalishSea/nowcast-green.201905/' \n",
    "FNAME_HEAD = 'SalishSea_1d_'\n",
    "FNAME_TAIL = '_grid_T.nc' \n",
    "\n",
    "# 输出目录\n",
    "OUT_DIR = '/home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA/'\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)\n",
    "    print(f\"Created output directory: {OUT_DIR}\")\n",
    "\n",
    "# 变量设置\n",
    "VAR_SALINITY = 'vosaline'\n",
    "VAR_LAT = 'nav_lat'\n",
    "VAR_LON = 'nav_lon'\n",
    "\n",
    "# 分析参数\n",
    "YEARS_TO_COMPARE = [2011, 2018]\n",
    "START_MONTH, START_DAY = 5, 1   # May 1st\n",
    "END_MONTH, END_DAY = 8, 31      # Aug 31st\n",
    "\n",
    "SPATIAL_SUBSAMPLE_STEP = 8 \n",
    "N_COMPONENTS = 3  # 只对比前3个模态通常就够了\n",
    "\n",
    "# --- 2. Data Loading Helper (Robust Land Masking) ---\n",
    "\n",
    "def get_file_path(date_obj):\n",
    "    indir_date = date_obj.strftime('%d%b%y').lower() + '/'\n",
    "    fname_date = date_obj.strftime('%Y%m%d')\n",
    "    return os.path.join(BASE_DIR, indir_date, FNAME_HEAD + fname_date + '_' + fname_date + FNAME_TAIL)\n",
    "\n",
    "def load_daily_sss(date_obj, step):\n",
    "    \"\"\"\n",
    "    Loads one day of SSS data.\n",
    "    Returns: (sss_flat_clean, lon_2d, lat_2d, valid_mask_1d)\n",
    "    \"\"\"\n",
    "    fpath = get_file_path(date_obj)\n",
    "    if not os.path.exists(fpath):\n",
    "        return None, None, None, None\n",
    "    \n",
    "    try:\n",
    "        with nc.Dataset(fpath, 'r') as ncfile:\n",
    "            sss = ncfile.variables[VAR_SALINITY][0, 0, ::step, ::step]\n",
    "            lon = ncfile.variables[VAR_LON][::step, ::step]\n",
    "            lat = ncfile.variables[VAR_LAT][::step, ::step]\n",
    "            \n",
    "            # Masking: Lon != 0 AND SSS is not NaN\n",
    "            mask_valid = (lon != 0.0) & (~np.isnan(sss)) & (sss < 1000) # Simple range check\n",
    "            \n",
    "            # Flatten everything\n",
    "            sss_flat = sss.flatten()\n",
    "            mask_flat = mask_valid.flatten()\n",
    "            \n",
    "            # Apply mask\n",
    "            sss_clean = sss_flat[mask_flat]\n",
    "            \n",
    "            return sss_clean, lon, lat, mask_flat\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {date_obj}: {e}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "# --- 3. Single Year Analysis Engine ---\n",
    "\n",
    "def analyze_year(year):\n",
    "    \"\"\"\n",
    "    Runs PCA for a single year's summer period.\n",
    "    Returns a dictionary with all results needed for plotting.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Analyzing Year {year} (May 1 - Aug 31) ---\")\n",
    "    start_date = datetime.date(year, START_MONTH, START_DAY)\n",
    "    end_date = datetime.date(year, END_MONTH, END_DAY)\n",
    "    \n",
    "    data_list = []\n",
    "    dates_list = []\n",
    "    \n",
    "    # Static grid info (captured from first valid day)\n",
    "    grid_lon, grid_lat, grid_mask = None, None, None\n",
    "    original_shape = None\n",
    "\n",
    "    curr = start_date\n",
    "    while curr <= end_date:\n",
    "        vec, lon, lat, mask = load_daily_sss(curr, SPATIAL_SUBSAMPLE_STEP)\n",
    "        if vec is not None:\n",
    "            if grid_lon is None:\n",
    "                grid_lon, grid_lat, grid_mask = lon, lat, mask\n",
    "                original_shape = lon.shape\n",
    "            \n",
    "            # Consistency check\n",
    "            if vec.shape[0] != grid_mask.sum():\n",
    "                print(f\"  Skipping {curr}: Grid mismatch (Mask len {grid_mask.sum()} vs Data {vec.shape[0]})\")\n",
    "            else:\n",
    "                data_list.append(vec)\n",
    "                dates_list.append(curr)\n",
    "        curr += datetime.timedelta(days=1)\n",
    "        \n",
    "    if not data_list:\n",
    "        return None\n",
    "    \n",
    "    # PCA Execution\n",
    "    X = np.array(data_list)\n",
    "    print(f\"  Data shape: {X.shape}\")\n",
    "    \n",
    "    pca = PCA(n_components=N_COMPONENTS)\n",
    "    # Fit on centered data\n",
    "    pcs = pca.fit_transform(X - X.mean(axis=0)) \n",
    "    eofs = pca.components_\n",
    "    var_ratio = pca.explained_variance_ratio_\n",
    "    \n",
    "    # --- Auto-Flip Signs for Consistency ---\n",
    "    # PCA signs are arbitrary. We flip them so the maximum absolute value is always positive.\n",
    "    # This makes comparing maps between years much easier.\n",
    "    for i in range(N_COMPONENTS):\n",
    "        max_idx = np.argmax(np.abs(eofs[i]))\n",
    "        if eofs[i][max_idx] < 0:\n",
    "            eofs[i] *= -1\n",
    "            pcs[:, i] *= -1 # Must flip PC time series too!\n",
    "            \n",
    "    return {\n",
    "        'year': year,\n",
    "        'pcs': pcs, # (Time, Modes)\n",
    "        'eofs': eofs, # (Modes, Space)\n",
    "        'var': var_ratio,\n",
    "        'dates': dates_list,\n",
    "        'lon': grid_lon,\n",
    "        'lat': grid_lat,\n",
    "        'mask': grid_mask,\n",
    "        'shape': original_shape\n",
    "    }\n",
    "\n",
    "# --- 4. Comparison Plotting Functions ---\n",
    "\n",
    "def plot_side_by_side_spatial(res1, res2, mode_idx):\n",
    "    \"\"\"Plots the Spatial Mode (EOF) of Year 1 and Year 2 side by side.\"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    # Shared settings\n",
    "    extent = [-125.5, -122, 48, 50.5]\n",
    "    levels = np.linspace(-0.15, 0.15, 41) # Fixed scale for easier comparison!\n",
    "    # Note: You might need to adjust levels if EOF values are very small/large\n",
    "    \n",
    "    results_list = [res1, res2]\n",
    "    \n",
    "    for k in range(2):\n",
    "        res = results_list[k]\n",
    "        ax = fig.add_subplot(1, 2, k+1, projection=ccrs.Mercator(central_longitude=-124))\n",
    "        ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "        \n",
    "        # Reconstruct 2D field\n",
    "        eof_1d = res['eofs'][mode_idx]\n",
    "        eof_2d_flat = np.full(res['mask'].shape, np.nan)\n",
    "        eof_2d_flat[res['mask']] = eof_1d\n",
    "        eof_2d = eof_2d_flat.reshape(res['shape'])\n",
    "        \n",
    "        # Adaptive Color Limits (override fixed levels if needed)\n",
    "        limit = np.nanmax(np.abs(eof_2d))\n",
    "        current_levels = np.linspace(-limit, limit, 40)\n",
    "        \n",
    "        cf = ax.contourf(res['lon'], res['lat'], eof_2d, \n",
    "                         levels=current_levels, cmap='RdBu_r', \n",
    "                         transform=ccrs.PlateCarree(), extend='both')\n",
    "        \n",
    "        ax.add_feature(cfeature.LAND, color='lightgray', zorder=2)\n",
    "        ax.add_feature(cfeature.COASTLINE, linewidth=0.8, zorder=3)\n",
    "        \n",
    "        ax.set_title(f\"{res['year']} EOF-{mode_idx+1}\\n(Explains {res['var'][mode_idx]*100:.1f}%)\", fontsize=14)\n",
    "        plt.colorbar(cf, ax=ax, shrink=0.8, orientation='horizontal', pad=0.05)\n",
    "\n",
    "    plt.suptitle(f\"Comparison of Spatial Mode {mode_idx+1} (Summer)\", fontsize=16)\n",
    "    \n",
    "    save_path = os.path.join(OUT_DIR, f\"Compare_Spatial_Mode_{mode_idx+1}.png\")\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"Saved comparison map: {save_path}\")\n",
    "\n",
    "def plot_overlaid_timeseries(res1, res2, mode_idx):\n",
    "    \"\"\"Plots PC time series overlaid on a Day-of-Year axis.\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Helper to get day of year\n",
    "    def get_doy(dates):\n",
    "        return [d.timetuple().tm_yday for d in dates]\n",
    "    \n",
    "    doy1 = get_doy(res1['dates'])\n",
    "    pc1 = res1['pcs'][:, mode_idx]\n",
    "    \n",
    "    doy2 = get_doy(res2['dates'])\n",
    "    pc2 = res2['pcs'][:, mode_idx]\n",
    "    \n",
    "    plt.plot(doy1, pc1, 'r-', lw=2, alpha=0.8, label=f\"{res1['year']} (Var: {res1['var'][mode_idx]*100:.1f}%)\")\n",
    "    plt.plot(doy2, pc2, 'b--', lw=2, alpha=0.8, label=f\"{res2['year']} (Var: {res2['var'][mode_idx]*100:.1f}%)\")\n",
    "    \n",
    "    plt.xlabel(\"Day of Year (May 1 is approx Day 121)\")\n",
    "    plt.ylabel(\"PC Amplitude\")\n",
    "    plt.title(f\"PC-{mode_idx+1} Time Series Comparison\")\n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "    plt.legend()\n",
    "    \n",
    "    save_path = os.path.join(OUT_DIR, f\"Compare_TimeSeries_PC_{mode_idx+1}.svg\")\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"Saved comparison TS: {save_path}\")\n",
    "\n",
    "# --- 5. Main Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Analyze 2011\n",
    "    res_2011 = analyze_year(2011)\n",
    "    \n",
    "    # 2. Analyze 2018\n",
    "    res_2018 = analyze_year(2018)\n",
    "    \n",
    "    if res_2011 and res_2018:\n",
    "        print(\"\\n--- Generating Comparison Plots ---\")\n",
    "        \n",
    "        # Compare first 3 modes\n",
    "        for i in range(N_COMPONENTS):\n",
    "            # A. Spatial Comparison\n",
    "            plot_side_by_side_spatial(res_2011, res_2018, mode_idx=i)\n",
    "            \n",
    "            # B. Time Series Comparison\n",
    "            plot_overlaid_timeseries(res_2011, res_2018, mode_idx=i)\n",
    "            \n",
    "        print(f\"\\nDone! Check folder: {OUT_DIR}\")\n",
    "        print(\"Tip: If EOF-1 maps look similar (e.g., both river plume patterns), you can safely combine years.\")\n",
    "    else:\n",
    "        print(\"Error: Could not process both years successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921c995e",
   "metadata": {},
   "source": [
    "The 2 yr case was a little weird. Mode 2 can be explained as Wind-Driven Plume Steering, or the turning of Fraser Plume caused by wind. Mode 3 was explained as Cross-Channel / Upwelling. We can use 10yr-summer daily data to verify it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fa49e0",
   "metadata": {},
   "source": [
    "## PCA on 10-year Summers (2010-2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51314700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Starting Decade Analysis (2010-2019) ===\n",
      "  Loading year 2019...\n",
      "Data Loading Done. Total Samples: 1230\n",
      "Matrix Shape: (1230, 2880)\n",
      "Computing PCA...\n",
      "Standardizing signs...\n",
      "Saving CSV...\n",
      "SUCCESS!\n",
      "CSV saved to: /home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA_10yr/PCA_Decade_TimeSeries_2010_2019.csv\n",
      "Plotting Data saved to: /home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA_10yr/PCA_Decade_Spatial_Data.npz\n"
     ]
    }
   ],
   "source": [
    "# SSS_PCA_Decade_Calc.py\n",
    "# 1. Loads SSS for Summer (May 1 - Aug 31) from 2010 to 2019.\n",
    "# 2. Performs PCA (EOF analysis).\n",
    "# 3. Saves PCs to CSV and all matrices to .npz for fast plotting.\n",
    "\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# --- Configuration ---\n",
    "# !!! 修改路径 !!!\n",
    "BASE_DIR = '/results2/SalishSea/nowcast-green.201905/' \n",
    "FNAME_HEAD = 'SalishSea_1d_'\n",
    "FNAME_TAIL = '_grid_T.nc' \n",
    "OUT_DIR = '/home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA_10yr/'\n",
    "\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)\n",
    "\n",
    "# 时间范围: 2010-2019, 每年 5.1 - 8.31\n",
    "YEARS = range(2010, 2020) \n",
    "START_MD = (5, 1)\n",
    "END_MD = (8, 31)\n",
    "\n",
    "SPATIAL_STEP = 8  # 空间降采样步长\n",
    "N_MODES = 6       #哪怕你只看前3个，算的时候多存几个没坏处\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def get_file_path(date_obj):\n",
    "    indir = date_obj.strftime('%d%b%y').lower() + '/'\n",
    "    fname = date_obj.strftime('%Y%m%d')\n",
    "    return os.path.join(BASE_DIR, indir, FNAME_HEAD + fname + '_' + fname + FNAME_TAIL)\n",
    "\n",
    "def load_daily_sss(date_obj, step):\n",
    "    \"\"\"Loads, subsamples, and cleans one day of data.\"\"\"\n",
    "    path = get_file_path(date_obj)\n",
    "    if not os.path.exists(path):\n",
    "        return None, None, None, None\n",
    "    try:\n",
    "        with nc.Dataset(path, 'r') as f:\n",
    "            # Load SSS (Time=0, Depth=0)\n",
    "            sss = f.variables['vosaline'][0, 0, ::step, ::step]\n",
    "            lon = f.variables['nav_lon'][::step, ::step]\n",
    "            lat = f.variables['nav_lat'][::step, ::step]\n",
    "            \n",
    "            # Masking: Remove (0,0) artifacts and NaNs\n",
    "            # SalishSeaCast model uses 0 for land in coords sometimes, or masked arrays\n",
    "            mask = (lon != 0) & (~np.isnan(sss)) & (sss < 100) # Simple validity check\n",
    "            \n",
    "            return sss.flatten()[mask.flatten()], lon, lat, mask.flatten()\n",
    "    except:\n",
    "        return None, None, None, None\n",
    "\n",
    "# --- Main Processing ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"=== Starting Decade Analysis (2010-2019) ===\")\n",
    "    \n",
    "    data_matrix = []\n",
    "    time_index = []\n",
    "    \n",
    "    # Grid metadata (captured from the first valid file)\n",
    "    grid_lon, grid_lat, grid_mask = None, None, None\n",
    "    original_shape = None\n",
    "    \n",
    "    # 1. Loop through all dates\n",
    "    for year in YEARS:\n",
    "        d_start = datetime.date(year, *START_MD)\n",
    "        d_end = datetime.date(year, *END_MD)\n",
    "        curr = d_start\n",
    "        print(f\"  Loading year {year}...\", end='\\r')\n",
    "        \n",
    "        while curr <= d_end:\n",
    "            vec, lon, lat, mask = load_daily_sss(curr, SPATIAL_STEP)\n",
    "            \n",
    "            if vec is not None:\n",
    "                if grid_lon is None:\n",
    "                    grid_lon, grid_lat, grid_mask = lon, lat, mask\n",
    "                    original_shape = lon.shape\n",
    "                \n",
    "                # Double check grid consistency\n",
    "                if len(vec) == grid_mask.sum():\n",
    "                    data_matrix.append(vec)\n",
    "                    time_index.append(curr)\n",
    "            \n",
    "            curr += datetime.timedelta(days=1)\n",
    "    \n",
    "    print(f\"\\nData Loading Done. Total Samples: {len(data_matrix)}\")\n",
    "    \n",
    "    # 2. PCA Calculation\n",
    "    X = np.array(data_matrix)\n",
    "    print(f\"Matrix Shape: {X.shape}\")\n",
    "    \n",
    "    # De-mean (Anomaly)\n",
    "    X_mean = X.mean(axis=0)\n",
    "    X_anom = X - X_mean\n",
    "    \n",
    "    print(\"Computing PCA...\")\n",
    "    pca = PCA(n_components=N_MODES)\n",
    "    PCs = pca.fit_transform(X_anom)   # (Time, Modes)\n",
    "    EOFs = pca.components_            # (Modes, Space)\n",
    "    Var = pca.explained_variance_ratio_\n",
    "    \n",
    "    # --- Sign Correction (Important for 10-year consistency) ---\n",
    "    # Ensure the maximum amplitude of the spatial pattern is positive\n",
    "    print(\"Standardizing signs...\")\n",
    "    for i in range(N_MODES):\n",
    "        max_idx = np.argmax(np.abs(EOFs[i]))\n",
    "        if EOFs[i][max_idx] < 0:\n",
    "            EOFs[i] *= -1\n",
    "            PCs[:, i] *= -1\n",
    "            \n",
    "    # 3. Saving Results\n",
    "    \n",
    "    # A. Save Time Series to CSV (User Request)\n",
    "    print(\"Saving CSV...\")\n",
    "    df_pcs = pd.DataFrame(PCs, columns=[f'PC_{i+1}' for i in range(N_MODES)])\n",
    "    df_pcs['Date'] = time_index\n",
    "    df_pcs['Year'] = [d.year for d in time_index]\n",
    "    df_pcs['DOY'] = [d.timetuple().tm_yday for d in time_index] # Day of Year\n",
    "    \n",
    "    csv_path = os.path.join(OUT_DIR, 'PCA_Decade_TimeSeries_2010_2019.csv')\n",
    "    df_pcs.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # B. Save Matrices for Plotting (Pickle/Numpy)\n",
    "    # This saves EVERYTHING needed to reconstruct the plots without raw data\n",
    "    npy_path = os.path.join(OUT_DIR, 'PCA_Decade_Spatial_Data.npz')\n",
    "    np.savez(npy_path, \n",
    "             eofs=EOFs, \n",
    "             variance=Var, \n",
    "             lon=grid_lon, \n",
    "             lat=grid_lat, \n",
    "             mask=grid_mask, \n",
    "             shape=original_shape,\n",
    "             mean_state=X_mean)\n",
    "    \n",
    "    print(f\"SUCCESS!\\nCSV saved to: {csv_path}\\nPlotting Data saved to: {npy_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6de3832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed data...\n",
      "--- Plotting Mode 1 ---\n",
      "Saved Map: /home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA_10yr/Decade_EOF_Mode_1.svg\n",
      "Saved TS: /home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA_10yr/Decade_PC_1_TimeSeries.svg\n",
      "Saved Seasonal Plot: /home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA_10yr/Decade_PC_1_Seasonality.svg\n",
      "--- Plotting Mode 2 ---\n",
      "Saved Map: /home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA_10yr/Decade_EOF_Mode_2.svg\n",
      "Saved TS: /home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA_10yr/Decade_PC_2_TimeSeries.svg\n",
      "Saved Seasonal Plot: /home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA_10yr/Decade_PC_2_Seasonality.svg\n",
      "--- Plotting Mode 3 ---\n",
      "Saved Map: /home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA_10yr/Decade_EOF_Mode_3.svg\n",
      "Saved TS: /home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA_10yr/Decade_PC_3_TimeSeries.svg\n",
      "Saved Seasonal Plot: /home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA_10yr/Decade_PC_3_Seasonality.svg\n",
      "All plots generated.\n"
     ]
    }
   ],
   "source": [
    "# SSS_PCA_Decade_Plot.py\n",
    "# Reads the pre-calculated PCA results and generates high-quality plots.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import os\n",
    "\n",
    "# --- Config ---\n",
    "# 指向第一步生成的目录\n",
    "IN_DIR = '/home/jqiu/Programing/Projects/analysis-junqi/Diatom_vs_Flagellate_Report/Results_PCA_10yr/'\n",
    "\n",
    "CSV_PATH = os.path.join(IN_DIR, 'PCA_Decade_TimeSeries_2010_2019.csv')\n",
    "NPY_PATH = os.path.join(IN_DIR, 'PCA_Decade_Spatial_Data.npz')\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"Loading pre-computed data...\")\n",
    "data = np.load(NPY_PATH, allow_pickle=True)\n",
    "df_pcs = pd.read_csv(CSV_PATH, parse_dates=['Date'])\n",
    "\n",
    "eofs = data['eofs']\n",
    "var_ratio = data['variance']\n",
    "lon = data['lon']\n",
    "lat = data['lat']\n",
    "mask = data['mask']     # 1D boolean mask\n",
    "grid_shape = data['shape'] # Original 2D shape (y, x)\n",
    "\n",
    "# --- 2. Plotting Functions ---\n",
    "\n",
    "def plot_spatial_mode(mode_idx):\n",
    "    \"\"\"Plots the 2D spatial pattern of a specific mode.\"\"\"\n",
    "    # Reconstruct 2D Field from 1D clean vector\n",
    "    eof_1d = eofs[mode_idx]\n",
    "    \n",
    "    # Create full grid filled with NaNs\n",
    "    full_field = np.full(mask.shape, np.nan)\n",
    "    # Fill in valid points\n",
    "    full_field[mask] = eof_1d\n",
    "    # Reshape to 2D\n",
    "    eof_2d = full_field.reshape(grid_shape)\n",
    "    \n",
    "    # Plot\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.Mercator(central_longitude=-124))\n",
    "    ax.set_extent([-125.5, -122, 48, 50.5], crs=ccrs.PlateCarree())\n",
    "    \n",
    "    # Adaptive Color Limits (Symmetric)\n",
    "    limit = np.nanmax(np.abs(eof_2d))\n",
    "    levels = np.linspace(-limit, limit, 41)\n",
    "    \n",
    "    cf = ax.contourf(lon, lat, eof_2d, levels=levels, cmap='RdBu_r', \n",
    "                     transform=ccrs.PlateCarree(), extend='both')\n",
    "    \n",
    "    ax.add_feature(cfeature.LAND, color='lightgray', zorder=2)\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.8, zorder=3)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':', zorder=3)\n",
    "    \n",
    "    cbar = plt.colorbar(cf, ax=ax, shrink=0.7, pad=0.05)\n",
    "    cbar.set_label('EOF Amplitude')\n",
    "    \n",
    "    title = f\"Mode {mode_idx+1} Spatial Pattern (Explains {var_ratio[mode_idx]*100:.1f}%)\"\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    \n",
    "    save_name = os.path.join(IN_DIR, f'Decade_EOF_Mode_{mode_idx+1}.svg')\n",
    "    plt.savefig(save_name, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved Map: {save_name}\")\n",
    "\n",
    "def plot_time_series_10years(mode_idx):\n",
    "    \"\"\"Plots the full 10-year time series.\"\"\"\n",
    "    pc_col = f'PC_{mode_idx+1}'\n",
    "    \n",
    "    plt.figure(figsize=(15, 4))\n",
    "    \n",
    "    # Plot the line\n",
    "    plt.plot(df_pcs['Date'], df_pcs[pc_col], 'k-', linewidth=0.8, alpha=0.8)\n",
    "    \n",
    "    # Highlight 2011 and 2018 (Your specific interest)\n",
    "    # Masking for colors\n",
    "    subset_2011 = df_pcs[df_pcs['Year'] == 2011]\n",
    "    plt.plot(subset_2011['Date'], subset_2011[pc_col], 'r-', linewidth=1.5, label='2011 (Wet/High Flow)')\n",
    "    \n",
    "    subset_2018 = df_pcs[df_pcs['Year'] == 2018]\n",
    "    plt.plot(subset_2018['Date'], subset_2018[pc_col], 'b-', linewidth=1.5, label='2018 (Dry/Low Flow)')\n",
    "    \n",
    "    plt.ylabel('PC Amplitude')\n",
    "    plt.title(f\"Mode {mode_idx+1} Time Series (2010-2019)\", fontsize=14)\n",
    "    plt.grid(True, linestyle=':', alpha=0.5)\n",
    "    plt.legend()\n",
    "    \n",
    "    save_name = os.path.join(IN_DIR, f'Decade_PC_{mode_idx+1}_TimeSeries.svg')\n",
    "    plt.savefig(save_name, dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved TS: {save_name}\")\n",
    "\n",
    "def plot_doy_overlay(mode_idx):\n",
    "    \"\"\"Overlays all years on a Day-of-Year axis to see seasonal consistency.\"\"\"\n",
    "    pc_col = f'PC_{mode_idx+1}'\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot background years (Gray)\n",
    "    for year in df_pcs['Year'].unique():\n",
    "        subset = df_pcs[df_pcs['Year'] == year]\n",
    "        if year not in [2011, 2018]:\n",
    "            plt.plot(subset['DOY'], subset[pc_col], color='gray', alpha=0.3, linewidth=1)\n",
    "            \n",
    "    # Highlight specific years\n",
    "    s2011 = df_pcs[df_pcs['Year'] == 2011]\n",
    "    plt.plot(s2011['DOY'], s2011[pc_col], 'r-', linewidth=2, label='2011')\n",
    "    \n",
    "    s2018 = df_pcs[df_pcs['Year'] == 2018]\n",
    "    plt.plot(s2018['DOY'], s2018[pc_col], 'b--', linewidth=2, label='2018')\n",
    "    \n",
    "    plt.xlabel('Day of Year')\n",
    "    plt.ylabel('PC Amplitude')\n",
    "    plt.title(f\"Mode {mode_idx+1}: Seasonal Variability (Overlaid)\", fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.5)\n",
    "    \n",
    "    save_name = os.path.join(IN_DIR, f'Decade_PC_{mode_idx+1}_Seasonality.svg')\n",
    "    plt.savefig(save_name, dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved Seasonal Plot: {save_name}\")\n",
    "\n",
    "# --- 3. Execute Plotting ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Plot top 3 modes\n",
    "    for i in range(3):\n",
    "        print(f\"--- Plotting Mode {i+1} ---\")\n",
    "        plot_spatial_mode(i)\n",
    "        plot_time_series_10years(i)\n",
    "        plot_doy_overlay(i)\n",
    "        \n",
    "    print(\"All plots generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeddc1b",
   "metadata": {},
   "source": [
    "## Method Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3aa6b8",
   "metadata": {},
   "source": [
    "In detail, we can say:\n",
    "\n",
    "To investigate the spatiotemporal variability of the Fraser River plume and its response to wind forcing, we performed an Empirical Orthogonal Function (EOF) analysis, also known as Principal Component Analysis (PCA), on the model-simulated Sea Surface Salinity (SSS) fields.\n",
    "\n",
    "The analysis utilizes daily-averaged SSS output from the SalishSeaCast model (version 201905) covering a ten-year period from 2010 to 2019. For each year, we extracted data for the extended summer season, defined as May 1st to August 31st, to capture the full progression of the Fraser River freshet and the dominant summer wind patterns.\n",
    "\n",
    "Data Preprocessing: To focus on synoptic-scale variability (e.g., wind-driven plume advection) while filtering out high-frequency tidal oscillations, daily averaged fields were selected. Spatially, the model grid was subsampled by a factor of 8 in both zonal and meridional directions to reduce computational cost while preserving mesoscale features. Land points and model boundary artifacts were masked out.\n",
    "\n",
    "PCA Decomposition: The 3D SSS data (time, latitude, longitude) were flattened into a 2D matrix X(t,s), where t represents the daily time steps (N=1230 days total) and s represents the spatial grid points. The temporal mean at each grid point was subtracted to obtain the SSS anomaly field X \n",
    "′\n",
    " . The PCA was then performed on the covariance matrix of X \n",
    "′\n",
    " to decompose the variability into orthogonal spatial modes (EOFs) and their corresponding temporal coefficients (Principal Components, PCs).\n",
    "\n",
    "The first few modes were retained for analysis, as they represent the dominant coherent patterns of salinity variability in the Salish Sea. The sign of the EOFs was standardized such that the maximum absolute amplitude is positive, ensuring consistency across different modes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d29601c",
   "metadata": {},
   "source": [
    "But for short:\n",
    "\n",
    "Principal Component Analysis (PCA) of Summer SSS (2010–2019). We applied PCA to daily-averaged Sea Surface Salinity (SSS) anomalies from the SalishSeaCast model to identify dominant spatiotemporal patterns. The dataset covers the summer months (May 1 – Aug 31) over a decadal period (2010–2019). Daily averages were used to resolve synoptic wind events while removing tidal signals. The spatial grid was subsampled by a factor of 8. The data were centered by subtracting the long-term mean prior to decomposition. The resulting spatial modes (EOFs) and time series (PCs) describe the deviation of the plume structure from the mean state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce02ca2f",
   "metadata": {},
   "source": [
    "## Results Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a74f2c",
   "metadata": {},
   "source": [
    "Results: Spatiotemporal Variability of Summer Sea Surface Salinity\n",
    "\n",
    "The Principal Component Analysis (PCA) applied to the daily sea surface salinity (SSS) anomalies for the summers (May–August) of 2010–2019 reveals three dominant modes of variability. Together, these three modes explain approximately 67.5% of the total variance in the SSS field, capturing the primary drivers of the salinity structure in the Salish Sea: river discharge volume, wind-driven redistribution, and plume dispersion dynamics.\n",
    "\n",
    "1. The Seasonal Discharge Mode (EOF1)\n",
    "\n",
    "The first mode (EOF1) is the dominant component, accounting for 47.7% of the total variance (Fig. Xa). Spatially, this mode exhibits a coherent, monopole structure across the entire Strait of Georgia, with the highest amplitudes centered near the Fraser River mouth and extending into the central basin. The uniform sign of the spatial coefficients indicates that SSS variations associated with this mode occur in phase across the entire domain.\n",
    "\n",
    "Physically, EOF1 represents the seasonal accumulation and draining of the total freshwater volume within the Strait. It captures the primary response to the Fraser River freshet: a strong positive phase in the associated Principal Component (PC1) corresponds to periods of high river discharge, resulting in a widespread freshening of the surface layer. Conversely, negative phases correspond to periods of reduced discharge or increased salinity prior to the freshet peak. This mode serves as a proxy for the total freshwater budget of the system.\n",
    "\n",
    "2. The Wind-Driven Upwelling-Advection Dipole (EOF2)\n",
    "\n",
    "The second mode (EOF2) explains 13.6% of the variance and reveals a distinct north-south dipole structure (Fig. Xb). The zero-crossing line (nodal line) is situated approximately near the Fraser River mouth, separating the domain into northern and southern sub-basins with opposing salinity anomalies.\n",
    "\n",
    "Notably, the spatial morphology of this mode suggests a spatially coupled hydrodynamic response to the prevailing along-strait winds:\n",
    "\n",
    "In the Northern Strait: The spatial pattern is boundary-intensified, with strong anomalies concentrated along the eastern and western shallow margins (e.g., Texada Island and Malaspina Strait). This structure is consistent with wind-driven coastal upwelling, where northwesterly winds drive surface Ekman transport, inducing the upwelling of saline deep water along the boundaries.\n",
    "\n",
    "In the Southern Strait: The pattern is characterized by a broad, basin-wide anomaly extending towards the Gulf Islands and Boundary Pass. This reflects the meridional advection of the stratified Fraser River plume.\n",
    "\n",
    "Under typical summer conditions (northwesterly winds), this mode manifests as a southward extension of the fresh plume (freshening the south) coupled with upwelling-favorable conditions in the north (increasing salinity). During reversal events (southeasterly winds), the pattern inverts, pushing the plume northward and suppressing the northern upwelling.\n",
    "\n",
    "3. The Plume Dispersion Mode (EOF3)\n",
    "\n",
    "The third mode (EOF3) accounts for 6.2% of the variance and captures a cross-channel contrast (Fig. Xc). The spatial pattern highlights a dynamic opposition between the \"near-field\" region (immediate vicinity of the river mouth and southern tidal channels) and the \"far-field\" region (central Strait and northern basin).\n",
    "\n",
    "This mode represents the variability in plume retention versus dispersion. A positive phase (as shown in Fig. Xc, red near the mouth) indicates conditions where freshwater is confined close to the delta or trapped along the coast, likely due to weak mixing or specific tidal phases. A negative phase (blue near the mouth) suggests enhanced cross-channel spreading and effective mixing of freshwater into the ambient central basin. While explaining a smaller fraction of the total variance, this mode is significant for understanding the distinct plume geometry independent of the total discharge volume or wind direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45776f29",
   "metadata": {},
   "source": [
    "Mode 1 (单极子): \n",
    "\n",
    "这是一个整体性的变化，不是哪里多了哪里少了，而是整个池子水变淡了或变咸了。这是为了对应 Fraser River 的总流量。\n",
    "\n",
    "Mode 2: \n",
    "\n",
    "\"spatially coupled hydrodynamic response\"（空间耦合的水动力响应）。\n",
    "\n",
    "North: \"boundary-intensified\"（边界强化）和 \"consistent with wind-driven coastal upwelling\"。“海峡两岸变色”的现象，暗示了涌升流机制。\n",
    "\n",
    "South:  \"meridional advection\"（经向平流）。**(We will change the phase)** “一团水被推着走”的现象。\n",
    "\n",
    "因为北方是 Upwelling 主导，所以营养盐主要由这个物理过程控制……\n",
    "\n",
    "Mode 3 (扩散/滞留)：\n",
    "\n",
    "\"near-field vs. far-field\"（近场 vs 远场）\n",
    "\n",
    "解释为什么河口和海峡中间颜色相反。代表水是“堆在门口”还是“散开了”。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
