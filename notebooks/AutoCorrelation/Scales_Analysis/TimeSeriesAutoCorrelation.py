# TimeSeriesAutoCorrelation.py
# This program calculates the R=0.5 AutoCorrelation scale for multiple time steps
# and plots the statistical distribution of these scales.
# Generated by Gemini based on user request.

import matplotlib.pyplot as plt
import netCDF4 as nc
import numpy as np
import datetime
import os # 导入 os 库用于创建目录

# 1. 设定参数和文件路径

indir='/home/jqiu/Programing/Wind/'
indir_results='/home/jqiu/Programing/AutoCorrelation/Scales_Analysis/' # 使用新的结果目录
# 确保结果目录存在
os.makedirs(indir_results, exist_ok=True)

fnames=['hrdps_y2025m10d01.nc','hrdps_y2025m10d02.nc','hrdps_y2025m10d03.nc','hrdps_y2025m10d04.nc',
'hrdps_y2025m10d05.nc', 'hrdps_y2025m10d06.nc','hrdps_y2025m10d07.nc', 'hrdps_y2025m10d08.nc',
'hrdps_y2025m10d09.nc']

# 存储所有计算得到的 R=0.5 滞后距离（相关尺度）
x_scales = [] # 水平（X）方向的相关尺度
y_scales = [] # 垂直（Y）方向的相关尺度

# -----------------------------------------------------
# 2. 定义核心计算函数
# -----------------------------------------------------

# 定义寻找特定阈值交点的函数（与前一个程序中略有不同，专注于返回值）
def find_threshold_crossing(autocorr, threshold=0.5):
    """
    找到自相关函数沿中心线的从 1.0 衰减到指定阈值时的滞后距离。
    输入：autocorr - 一维自相关数组（已中心化）
    输出：lag_cross - 第一次达到阈值时的滞后距离，如果找不到则为 None
    """
    
    # 获取中心点索引
    center_idx = len(autocorr) // 2
    
    # 只考虑正向滞后，因为函数是对称的
    lags_pos = np.arange(0, len(autocorr) - center_idx) # 0, 1, 2, ...
    autocorr_pos = autocorr[center_idx:]
    
    # 查找小于或等于阈值的位置
    cross_indices = np.where(autocorr_pos <= threshold)[0]
    
    if len(cross_indices) > 0:
        # 第一次低于阈值的位置
        idx_low = cross_indices[0]
        
        # 如果是中心点本身（idx_low=0），说明整个场的相关性低于阈值（不应该出现，但作为保护）
        if idx_low == 0:
            return None 
            
        # 在 idx_low-1 和 idx_low 之间进行线性插值
        idx_high = idx_low - 1 # 上一个点，其值 > threshold
        
        # 实际滞后距离的索引值
        x1, x2 = lags_pos[idx_high], lags_pos[idx_low]
        # 自相关值
        y1, y2 = autocorr_pos[idx_high], autocorr_pos[idx_low]
        
        # 线性插值找到精确的交点 x_cross
        # 记住：y1 > threshold > y2
        # lag_cross = x1 + (threshold - y1) * (x2 - x1) / (y2 - y1)
        lag_cross = x1 + (threshold - y1) * (x2 - x1) / (y2 - y1)
        return lag_cross
    
    # 如果自相关值最低也未达到阈值（如 R=0.5），则返回 None
    return None

# -----------------------------------------------------
# 3. 循环读取数据并计算
# -----------------------------------------------------

print("开始批量计算空间自相关尺度 (R=0.5)...")

# 外层循环：遍历所有日期文件
for day_index, fname in enumerate(fnames):
    
    data_path = indir + fname
    if not os.path.exists(data_path):
        print(f"警告：文件 {fname} 未找到，跳过。")
        continue

    try:
        ds = nc.Dataset(data_path)
        u_wind_dataarray = ds.variables['u_wind']
        v_wind_dataarray = ds.variables['v_wind']
        
        # 假设所有文件的时间维度大小一致，或者使用实际维度
        num_time_steps = u_wind_dataarray.shape[0] 
        
        # 内层循环：遍历每天所有时间步
        for t_index in range(num_time_steps):
            
            # 读取当前时间步的风速分量
            u_wind = u_wind_dataarray[t_index,:,:]
            v_wind = v_wind_dataarray[t_index,:,:]
            
            # 2.1. 计算风速标量场 S
            wind_speed = np.sqrt(u_wind**2 + v_wind**2)
            
            # 2.2. 预处理：移除均值
            wind_speed_prime = wind_speed - np.mean(wind_speed)
            
            # 2.3. 使用 FFT 计算自相关
            fft_data = np.fft.fft2(wind_speed_prime)
            psd = np.abs(fft_data)**2
            autocorr_raw = np.fft.ifft2(psd).real
            autocorr_shifted = np.fft.fftshift(autocorr_raw)
            
            # 2.4. 标准化自相关函数
            # 检查分母是否为零（如果整个场的值都一样，则会发生）
            max_val = autocorr_shifted.max()
            if max_val == 0:
                print(f"时间步 {t_index} 的数据方差为零，跳过。")
                continue
                
            autocorr_normalized = autocorr_shifted / max_val

            # 2.5. 提取一维剖面并计算 R=0.5 尺度
            rows, cols = autocorr_normalized.shape
            center_row, center_col = rows // 2, cols // 2

            # 水平 (X) 方向
            autocorr_x = autocorr_normalized[center_row, :]
            scale_x = find_threshold_crossing(autocorr_x, threshold=0.5)
            if scale_x is not None:
                x_scales.append(scale_x)
            
            # 垂直 (Y) 方向
            autocorr_y = autocorr_normalized[:, center_col]
            scale_y = find_threshold_crossing(autocorr_y, threshold=0.5)
            if scale_y is not None:
                y_scales.append(scale_y)
                
        ds.close()
        print(f"文件 {fname} 处理完毕。")

    except Exception as e:
        print(f"处理文件 {fname} 时发生错误: {e}")
        if 'ds' in locals() and ds:
            ds.close()

print(f"所有文件处理完毕。共收集到 {len(x_scales)} 个 X 尺度和 {len(y_scales)} 个 Y 尺度。")

# -----------------------------------------------------
# 4. 统计结果可视化
# -----------------------------------------------------

if len(x_scales) > 0 and len(y_scales) > 0:
    plt.figure(figsize=(14, 6))

    # 绘制 X 方向相关尺度的直方图
    plt.subplot(1, 2, 1)
    plt.hist(x_scales, bins=20, edgecolor='black', alpha=0.7, color='skyblue')
    
    # 标注统计信息
    mean_x = np.mean(x_scales)
    std_x = np.std(x_scales)
    plt.axvline(mean_x, color='red', linestyle='--', label=f'Mean: {mean_x:.2f}')
    
    plt.title('Distribution of Horizontal (X) Correlation Scales (R=0.5)')
    plt.xlabel('Lag Distance (Index Units)')
    plt.ylabel('Frequency')
    plt.legend()
    plt.grid(axis='y', alpha=0.5)

    # 绘制 Y 方向相关尺度的直方图
    plt.subplot(1, 2, 2)
    plt.hist(y_scales, bins=20, edgecolor='black', alpha=0.7, color='lightcoral')
    
    # 标注统计信息
    mean_y = np.mean(y_scales)
    std_y = np.std(y_scales)
    plt.axvline(mean_y, color='red', linestyle='--', label=f'Mean: {mean_y:.2f}')
    
    plt.title('Distribution of Vertical (Y) Correlation Scales (R=0.5)')
    plt.xlabel('Lag Distance (Index Units)')
    plt.ylabel('Frequency')
    plt.legend()
    plt.grid(axis='y', alpha=0.5)

    plt.tight_layout()
    plot_filename = os.path.join(indir_results, 'R_05_Correlation_Scales_Distribution.png')
    plt.savefig(plot_filename)
    plt.show()
    print(f"结果图已保存到: {plot_filename}")
else:
    print("没有收集到足够的 R=0.5 相关尺度数据，无法绘图。请检查数据。")